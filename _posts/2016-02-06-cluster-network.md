---
layout: post
author: Mu Li
comments: true
title: 分布式深度学习——GPU集群网络
---

这是深度学习硬件的第二篇。
[前一篇](http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/)关注如何经济的
购买集群硬件达到最大的计算性能，这一篇关注集群网络。

## 为什么要关注集群网络

通常数据中心中网络设备的开销都不菲，少则占整体费用的百分之一二十，多则三四十。一
个极端例子是隔壁组买了个小集群，光交换机（40Gbits）花了十万刀，占了整体费用的一半了。

对于我们来说，网络的主要功能是分布式数据读取，和分布式训练中的数据通讯。前者好理
解，因为假如我有数T数据，那不太可能每台机器都复制一份，这对存储和维护开销都很大。
对于后者，现在也越来越多的人意识到了重要性。虽然主流上大家都是一机4卡或者8卡，而
且享受着GPU服从摩尔定律带来的优惠，但数据的增长和深度学习网络的复杂化仍然远远超
过单机计算性能的增长。

举个栗子，假设我们用一台插有4块Titan X的机器来在imagnet12数据（1.2m样本，1k类别）
上来训练模型。使用alexnet扫一轮几分钟就可以完成，使用google inception加BN稍微慢
点，一轮大约20分钟，迭代个50轮不到一天就完成了。但世界变化很快，每隔多久
inception v3出来了，比前一个版本慢了2.5倍。当所有人还把v3的结果重复出来的时候，
resnet拿冠军了，152层的版本至少是v3运算的2倍以上。而且这些模型比前面简单版本收敛
更慢，本来单机一天内能训练完成现在马上变成了一周以上。

人对于时间的感应，一分钟和十分钟区别不大，一小时和十小时还能忍，对一天和十天的区
别那就有些望而生畏了。而且imagenet 12并不是很大的数据，千万和亿级别的数据是训练可
以实用的模型的必须了。单机在上面完全不能胜任。

分布式的好处是，可以通过花钱把计算时间线性的递减。例如一台4卡机器
可能需要一万刀，那么再花一万刀，训练时间可以十天变五天，花上十万刀，那么早上起的
任务晚上就完成了。

<div class="message">
上述的线性提升只是在一定规模内成立。例如花上一百万刀很难吧时间从10天降到2小时。
当然也不是完全不可能。。。如果你准备烧一百万刀，请一定联系我！
</div>

虽然过去5年里不管是在公司还是在学校，我的主研究方向是分布式机器学习，但即使是3个
月前我仍然觉得分布式的深度学习训练仍然只是技术实力公司用用。但这几月从出去开会跟
人讨论，和
[mxnet](https://github.com/dmlc/mxnet/tree/master/example/image-classification)
分布式训练的使用来看，这个的普及
率远大于预期。我觉得主要原因有两点，一是计算量确实庞大，例如现在做个实验一般还是要跑
下imagenet类似规模的数据吧，未来很可能光弄个cifar10或者mnist已经打发不过去了。
二是硬件、分布式的算法和工具在数十个计算节点上已经很成熟了，性价比非常高。一般的
研究组大家都有个数台机器在手上，分布式能吧一次实验的时间减少数天，大家都乐意来折
腾这个。

算法和工具我想以后再讨论，这次主要是讲硬件。


## 什么样的集群网络够了

## 升级手记
